{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywkcKtNMKwKG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(1)\n",
        "rnn_layer = nn.RNN(input_size=5, hidden_size=2,\n",
        "                   num_layers=1, batch_first=True)\n",
        "w_xh = rnn_layer.weight_ih_l0 #2x5\n",
        "w_hh = rnn_layer.weight_hh_l0 #2x2\n",
        "b_xh = rnn_layer.bias_ih_l0 #2\n",
        "b_hh = rnn_layer.bias_hh_l0 #2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w_xh.shape, w_hh.shape, b_xh.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCMUayCBCOOR",
        "outputId": "e51d2f11-94b6-4623-81eb-133cf600f186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 5]), torch.Size([2, 2]), torch.Size([2]))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AV-HCLoZ1YP",
        "outputId": "c567c0c1-6e51-4196-8b91-c1a5f9de000b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Parameter containing:\n",
              "  tensor([[ 0.3643, -0.3121, -0.1371,  0.3319, -0.6657],\n",
              "          [ 0.4241, -0.1455,  0.3597,  0.0983, -0.0866]], requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([[ 0.1961,  0.0349],\n",
              "          [ 0.2583, -0.2756]], requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([-0.0516, -0.0637], requires_grad=True),\n",
              "  Parameter containing:\n",
              "  tensor([ 0.1025, -0.0028], requires_grad=True)]]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "rnn_layer.all_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erIaQUfbX0Gl"
      },
      "outputs": [],
      "source": [
        "x_seq = torch.tensor([[1.0]*5, [2.0]*5, [3.0]*5]).float()\n",
        "output, hn = rnn_layer(torch.reshape(x_seq, (1, 3, 5)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukq_vpe-ZbXZ",
        "outputId": "601eff70-f834-4a0e-8756-fe9ab16a8f05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[-0.3520,  0.5253],\n",
              "          [-0.6842,  0.7607],\n",
              "          [-0.8649,  0.9047]]], grad_fn=<TransposeBackward1>),\n",
              " tensor([[[-0.8649,  0.9047]]], grad_fn=<StackBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "output, hn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIlturyjb0qX",
        "outputId": "ab7cdf93-a6e0-48e8-b75a-f7aee23cfa67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time step 0 =>\n",
            "   Input           : [[1. 1. 1. 1. 1.]]\n",
            "   Hidden          : [[-0.4701929  0.5863904]]\n",
            "   Output (manual) : [[-0.3519801   0.52525216]]\n",
            "   RNN output      : [[-0.3519801   0.52525216]]\n",
            "\n",
            "Time step 1 =>\n",
            "   Input           : [[2. 2. 2. 2. 2.]]\n",
            "   Hidden          : [[-0.88883156  1.2364397 ]]\n",
            "   Output (manual) : [[-0.68424344  0.76074266]]\n",
            "   RNN output      : [[-0.68424344  0.76074266]]\n",
            "\n",
            "Time step 2 =>\n",
            "   Input           : [[3. 3. 3. 3. 3.]]\n",
            "   Hidden          : [[-1.3074702  1.8864892]]\n",
            "   Output (manual) : [[-0.8649416  0.9046636]]\n",
            "   RNN output      : [[-0.8649416  0.9046636]]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#manual\n",
        "out_man = []\n",
        "for t in range(3):\n",
        "  xt = torch.reshape(x_seq[t], (1, 5))\n",
        "  print(f\"Time step {t} =>\")\n",
        "  print(\"   Input           :\", xt.numpy())\n",
        "  ht = torch.matmul(xt, torch.transpose(w_xh, 0, 1)) + b_xh\n",
        "  print(\"   Hidden          :\", ht.detach().numpy())\n",
        "  if t>0:\n",
        "    prev_h = out_man[t-1]\n",
        "  else:\n",
        "    prev_h = torch.zeros((ht.shape))\n",
        "  ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
        "  ot = torch.tanh(ot)\n",
        "  out_man.append(ot)\n",
        "  print(\"   Output (manual) :\", ot.detach().numpy())\n",
        "  print(\"   RNN output      :\", output[:, t].detach().numpy())\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa3_wW04qzso",
        "outputId": "cfa546fe-0a18-49e7-b0af-49ef6821704f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.27.1)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext) (1.22.4)\n",
            "Requirement already satisfied: torchdata==0.6.1 in /usr/local/lib/python3.10/dist-packages (from torchtext) (0.6.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchtext) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.1->torchtext) (1.26.16)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchtext) (16.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchtext) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchtext) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install torchtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzIZDts5rIdk"
      },
      "outputs": [],
      "source": [
        "pip install portalocker>=2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66DQzy0CeG72"
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import IMDB\n",
        "\n",
        "train_dataset = IMDB(split=\"train\")\n",
        "test_dataset = IMDB(split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kvL0bKR9-JE"
      },
      "outputs": [],
      "source": [
        "#step 1: create the dataset\n",
        "from torch.utils.data.dataset import random_split\n",
        "torch.manual_seed(1)\n",
        "\n",
        "train_dataset, valid_dataset = random_split(list(train_dataset), [20000, 5000])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, valid_dataset = list(train_dataset)[:5000], list(valid_dataset)[:2000]"
      ],
      "metadata": {
        "id": "rEn1-IilDu_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSnjRqH1ruJY",
        "outputId": "df1c048d-3e41-406f-c292-3c6d6e49368e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab-size:  38717\n"
          ]
        }
      ],
      "source": [
        "#step 2: find unique tokens (words)\n",
        "import re\n",
        "from collections import Counter, OrderedDict\n",
        "\n",
        "def tokenizer(text):\n",
        "  text = re.sub(\"<[^>]*>\", \"\", text)\n",
        "  emoticons = re.findall(\n",
        "      \"(?::|;|=)(?:-)?(?:\\)|\\(|D|P)\", text.lower()\n",
        "  )\n",
        "  text = re.sub(\"[\\W]+\", \" \", text.lower() + \" \".join(emoticons).replace(\"-\", \"\"))\n",
        "  tokenized = text.split()\n",
        "  return tokenized\n",
        "\n",
        "token_counts = Counter()\n",
        "for label, line in train_dataset:\n",
        "  tokens = tokenizer(line)\n",
        "  token_counts.update(tokens)\n",
        "\n",
        "print(\"Vocab-size: \", len(token_counts))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikffA8tDeEas"
      },
      "outputs": [],
      "source": [
        "# step 3: encoding each unique token into integers\n",
        "from torchtext.vocab import vocab\n",
        "\n",
        "sorted_by_freq_tuples = sorted(\n",
        "    token_counts.items(), key=lambda x: x[1], reverse=True\n",
        ")\n",
        "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "vocab = vocab(ordered_dict)\n",
        "vocab.insert_token(\"<pad>\", 0)\n",
        "vocab.insert_token(\"<unk>\", 1)\n",
        "vocab.set_default_index(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W59hC7vZhjwD",
        "outputId": "6ca02160-a264-414c-99a3-37b422d45ff1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 7, 35, 472]\n"
          ]
        }
      ],
      "source": [
        "print([vocab[token] for token in ['this', 'is', 'an', 'example']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nch1Nkx8ntYs"
      },
      "outputs": [],
      "source": [
        "#step 3-A: define the functions for transformation\n",
        "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "label_pipeline = lambda x: 1. if x == \"pos\" else 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW0FJn-76W2v"
      },
      "outputs": [],
      "source": [
        "# step 3-B: wrap the encode and transformation function\n",
        "\n",
        "def collate_batch(batch):\n",
        "  label_list, text_list, lengths = [], [], []\n",
        "  for _label, _text in batch:\n",
        "    label_list.append(label_pipeline(_label))\n",
        "    processed_text = torch.tensor(text_pipeline(_text),\n",
        "                                  dtype=torch.int64)\n",
        "    text_list.append(processed_text)\n",
        "    lengths.append(processed_text.size(0))\n",
        "  label_list = torch.tensor(label_list)\n",
        "  lengths = torch.tensor(lengths)\n",
        "  padded_text_list = nn.utils.rnn.pad_sequence(\n",
        "      text_list, batch_first=True) # if true output shape TxBx* else BxTx*\n",
        "      #true olursa hepsinin uzunluğu aynı oluyor kısaca\n",
        "  return padded_text_list, label_list, lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUNjpMYa7VHH",
        "outputId": "c0659f55-a3c1-451a-f28b-d255ab763f3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "         [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "         [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "         [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.],\n",
              "         [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "a = torch.ones(3, 10)\n",
        "b = torch.full((4, 10), 2)\n",
        "c = torch.full((5, 10), 3)\n",
        "pad_sequence([a, b, c], batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqPU_KHQ7kOD",
        "outputId": "29bd3771-8f9a-49ba-c4b0-d37ca52d606f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "         [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]],\n",
              "\n",
              "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "         [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]],\n",
              "\n",
              "        [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "         [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [2., 2., 2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "         [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [3., 3., 3., 3., 3., 3., 3., 3., 3., 3.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "a = torch.ones(3, 10)\n",
        "b = torch.full((4, 10), 2)\n",
        "c = torch.full((5, 10), 3)\n",
        "pad_sequence([a, b, c])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSGt-f0B8xsa"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataloader = DataLoader(train_dataset, batch_size=4,\n",
        "                        shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLj9_qSf9OD6",
        "outputId": "f61a593f-17c7-4a9d-fca9-3695be03ca8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[   35,  1662,     7,   452,   710,     6,   282,     4,   832,     9,\n",
              "              4,    18,    45,     2,  1693,  2898,   182,    27,     7,    24,\n",
              "             99,  2001,  1662,    27,     7, 23238,  2555,  1244,  6690,   832,\n",
              "              5,     2,  5018,  9939,    36,     7,   155,   109,   877,     6,\n",
              "          11074,     2,   161,   137,    62,    27,  3215,  1454,     3,   900,\n",
              "           1908,     9,     6,  4239,     2,   158,    36,    14,   283,     4,\n",
              "          23239,     9,  5018,     3,    14,  7687,    34,  2555,     8,    51,\n",
              "            155,    29,     2,    61,    17,    11,  1909,   128,     6,   398,\n",
              "           1270,    26, 12549,  1029,    11,     7,    30,   971,    18,    16,\n",
              "          14576,   426,    34,  2825, 14577,  5019,     2,   942,  2899,     9,\n",
              "           2555,    13,   105,     9,   174,    98,    27,    51,  7688,  1762,\n",
              "             26,   717,    17,     2,   223,    16,     4,    54,   734,   225,\n",
              "            407,     2,   832,    32,    26,  3937,     3,    32,    26,  7689,\n",
              "           5292,  2556,  9016,     4,  2964,  1627,    15,     2,  1038,  3299,\n",
              "            158,     3,  8301,     7,   402,     9,    41,   223,    16,    41,\n",
              "            427,     3,  3395,   823,    37,    74,  3698,    15,  7688,   122,\n",
              "             31,   183,  3938,   619,   154,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [  213,   174,   711,     5,    11,    18,    10,   249,   113,    14,\n",
              "            189,    76,     8,    13,    24,   189,    76,     8,    13,   150,\n",
              "            189,    50,   147,    24,    90,     2,  5893,  8302,   105,    96,\n",
              "             28,  1856,   603,    19,    55,   159,    22,  1857,     8,     6,\n",
              "           1173,   364,     2,   361,    10,   141,   409,     4,   349,     5,\n",
              "           4793,  6691,  5570,  1286, 17692,    32,   226,     9,     2,   430,\n",
              "           1327,    13,  5893,    13,   992,     7,    90,    19,     2,    20,\n",
              "           1072,     4,    90,   600,    34,    24,   823,    53,     5,    68,\n",
              "            680,    10,   487,     8,     4,   738,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [   10,   120,    24,    28,    95,    74,   551,     9,   151,     2,\n",
              "           6692,  3137, 12550,  1012,   502,     2,  1061,  2306,     5, 11075,\n",
              "           6255,    19,    27,    65,    84,  2557,    38,     2,  6692,     3,\n",
              "             27,    65,    84,  2965,    34,    35, 11076,   158,   452, 23240,\n",
              "          23241,    10,    65,     2,   516,    12, 12550,    65,    94,     4,\n",
              "             50,    20,    19,     8,    65,    24,  3585,     2,  2498,    37,\n",
              "             33,  2557,    88,     3,  2184,   166,   158,    11,   547,   123,\n",
              "             24,   153,    69,   288,    13,   432,     2,  4090,    19,     2,\n",
              "           6692,  9017,     6,    29,   130,    73,    48,    10,   794,     8,\n",
              "             13,    24,     4,    90,    20,    19,     8,    13,    35,   201,\n",
              "              3,   396,   703,     2,   105,   883,     7,    54,    69,   237,\n",
              "              3,    10,    96,   125,     2,   104,    54,    69,    81,     2,\n",
              "            680,   207,     2,   106,   293,   104,     7,  1129,     3,  2966,\n",
              "            665,  5571,     3,  3939,  4576,   684,  3138,   386,   155,   288,\n",
              "             13,   138,     6,     2,  1694,   666,    30,  1472,    62,    63,\n",
              "           2447,    71,    40,    14,     4,   501,     9,    62,     8,  6693,\n",
              "             71,    14,     2,  3940,     5,  5572,  3479,     6,   202,     2,\n",
              "             18,    53,  2044,     3,   384,    12,  3479,   240,    43,     5,\n",
              "            261,     3,    68,  1328,     7,  9018,   865,    10,   102,     2,\n",
              "             20,   146,    28,    84,    53,  3941,     9,  2745,     5,    12,\n",
              "             10,   375,     2,  6692,    15,     4,    50,   703,     8,    13,\n",
              "             24,   875,    32,    31,    19,     8,    13,   396],\n",
              "         [14578,     7,     4,  5020,  1641,    12,  3216,     6,     4, 17693,\n",
              "            496,    40,    27,    82,  1521,     9,   122,     6, 17694,     2,\n",
              "             89,   311,   232,     9,   496,    33,    82,   365,     4, 17695,\n",
              "            809,    62,    82,   132,     9,     2,  1573,   346,     5, 14578,\n",
              "             32,     2,  2085,    49,   167,   292, 17694,    46,  1130,     6,\n",
              "           9940,     2, 14579,   128,     9,   496,     3,   467,     4,  2257,\n",
              "            739,   413,  4091,    34,   275,    30,   245,     2, 23242,     5,\n",
              "          14578,    82,    92,    41,  2153,     6,  1787,    56,     3,   488,\n",
              "            215,   506,     2,  3942,     2,   111,     7,   178,  1695,     3,\n",
              "            584,     5,     2,   156,   320,     4,   528,   176,     9,  1642,\n",
              "            279,  7158,     5,     2,    20,    25,   735,  1174,    62,   126,\n",
              "            109,    69,   817,    25,   178,  9019,    15,    70,   187,     6,\n",
              "             67,    53,   883,     5,     2,    64,     8,     7,    44,     4,\n",
              "             76, 23243, 23244,    13,    20,    16,   818,     5,   387,    60,\n",
              "           3699,     3,   395,   104,  2448,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0]]),\n",
              " tensor([0., 0., 0., 0.]),\n",
              " tensor([165,  86, 218, 145]))"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "next(iter(dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUQBVBYk9gd8"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                      shuffle=True, collate_fn=collate_batch)\n",
        "valid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n",
        "                     shuffle=False, collate_fn=collate_batch)\n",
        "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                     shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ha9YiPLACAXF",
        "outputId": "27166ff4-e3f9-47fc-bf65-097f0ccf3c61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.7039, -0.8321, -0.4651],\n",
            "         [-0.3203,  2.2408,  0.5566],\n",
            "         [-0.4643,  0.3046,  0.7046],\n",
            "         [-0.7106, -0.2959,  0.8356]],\n",
            "\n",
            "        [[-0.4643,  0.3046,  0.7046],\n",
            "         [ 0.0946, -0.3531,  0.9124],\n",
            "         [-0.3203,  2.2408,  0.5566],\n",
            "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n",
            "torch.Size([2, 4, 3])\n"
          ]
        }
      ],
      "source": [
        "embedding = nn.Embedding(\n",
        "    num_embeddings=10,\n",
        "    embedding_dim=3,\n",
        "    padding_idx=0)\n",
        "#a batch of 2 samples of a 4 indices each\n",
        "\n",
        "text_encoded_input = torch.LongTensor([[1,2,4,5],[4,3,2,0]]) # batchsize × input_length × embedding_dim,\n",
        "print(embedding(text_encoded_input))\n",
        "print(embedding(text_encoded_input).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgdP30fzIpMW",
        "outputId": "c58d8bf8-9d83-411f-8c88-09506c85d329"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (rnn): RNN(64, 32, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super().__init__()\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, num_layers=2,\n",
        "                      batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    _, hidden = self.rnn(x)\n",
        "    out = hidden[-1:, :, :] # we use the final hidden state\n",
        "                            # from the last hidden layer as\n",
        "                            # the input to the fully connected\n",
        "                            # layer\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "model = RNN(64, 32)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32tZVA4kKOs4",
        "outputId": "bb0249e6-92db-4e44-b60f-f6526b401a27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 32]), torch.Size([32, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "model.rnn.weight_ih_l1.shape, model.rnn.weight_ih_l0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4EUZOVSJgK5",
        "outputId": "6a7dd27b-d3c9-4698-93a3-2a32996f400d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 5, 32]), torch.Size([5, 3, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "model.rnn(torch.randn(5, 3, 64))[1].shape, model.rnn(torch.randn(5, 3, 64))[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TtKPVypRN8r",
        "outputId": "bae58363-f17a-4e09-aaa6-f4bb7a5d1c18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(38719, 20, padding_idx=0)\n",
              "  (rnn): LSTM(20, 32, batch_first=True)\n",
              "  (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, rnn_hidden_size,\n",
        "               fc_hidden_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size,\n",
        "                                  embed_dim,\n",
        "                                  padding_idx=0)\n",
        "    self.rnn = nn.LSTM(embed_dim, rnn_hidden_size,\n",
        "                       batch_first=True)\n",
        "    self.fc1 = nn.Linear(rnn_hidden_size, fc_hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(fc_hidden_size, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, text, lengths):\n",
        "    out = self.embedding(text)\n",
        "    out = nn.utils.rnn.pack_padded_sequence(\n",
        "        out, lengths.cpu().numpy(), enforce_sorted=False, batch_first=True)\n",
        "    out, (hidden, cell) = self.rnn(out)\n",
        "    out = hidden[-1, :, :]\n",
        "    out = self.fc1(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "embed_dim = 20\n",
        "rnn_hidden_size = 32\n",
        "fc_hidden_size = 32\n",
        "torch.manual_seed(1)\n",
        "model = RNN(vocab_size, embed_dim, rnn_hidden_size, fc_hidden_size)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3S4noF2TzJ_"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dlKXiDknSmAB"
      },
      "outputs": [],
      "source": [
        "def train(dataloader):\n",
        "  model.train()\n",
        "  total_acc, total_loss = 0, 0\n",
        "  for text_batch, label_batch, lengths in dataloader:\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(text_batch, lengths)[:, 0]\n",
        "    loss = loss_fn(pred, label_batch)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_acc += (\n",
        "        (pred >= .5).float() == label_batch\n",
        "    ).float().sum().item()\n",
        "    total_loss += loss.item()*label_batch.size(0)\n",
        "  return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgqcdoWfTcRT"
      },
      "outputs": [],
      "source": [
        "def evaluate(dataloader):\n",
        "  model.eval()\n",
        "  total_acc, total_loss = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for text_batch, label_batch, lengths in dataloader:\n",
        "      pred = model(text_batch, lengths)[:, 0]\n",
        "      loss = loss_fn(pred, label_batch)\n",
        "      total_acc += (\n",
        "        (pred>=0.5).float() == label_batch\n",
        "      ).float().sum().item()\n",
        "      total_loss += loss.item()*label_batch.size(0)\n",
        "  return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRYSxeHqT6mo",
        "outputId": "e45df1d1-4f98-41b9-d346-74763553c59b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 accuracy: 1.0000 val_accuracy: 1.0000\n",
            "Epoch 1 accuracy: 1.0000 val_accuracy: 1.0000\n",
            "Epoch 2 accuracy: 1.0000 val_accuracy: 1.0000\n",
            "Epoch 3 accuracy: 1.0000 val_accuracy: 1.0000\n",
            "Epoch 4 accuracy: 1.0000 val_accuracy: 1.0000\n",
            "Epoch 5 accuracy: 1.0000 val_accuracy: 1.0000\n",
            "Epoch 6 accuracy: 1.0000 val_accuracy: 1.0000\n",
            "Epoch 7 accuracy: 1.0000 val_accuracy: 1.0000\n",
            "Epoch 8 accuracy: 1.0000 val_accuracy: 1.0000\n",
            "Epoch 9 accuracy: 1.0000 val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "torch.manual_seed(1)\n",
        "for epoch in range(num_epochs):\n",
        "  acc_train, loss_train = train(train_dl)\n",
        "  acc_valid, loss_valid = evaluate(valid_dl)\n",
        "  print(f'Epoch {epoch} accuracy: {acc_train:.4f}'\n",
        "        f' val_accuracy: {acc_valid:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(train_dl))[0][0].__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_WtFOCaMavf",
        "outputId": "a549e583-d411-44ad-f1ed-479bc0e4b8ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "475"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(test_dl))[0][0].__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AOTO_7wO0LP",
        "outputId": "977f9ab4-d591-4e35-cefe-ec7c0bd9e45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "446"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU7O0RDHq69r"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/1268/1268-0.txt\"\n",
        "uf = urllib.request.urlopen(url)\n",
        "html = uf.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZiGk28FrthD"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://www.gutenberg.org/files/1268/1268-0.txt\"\n",
        "html = requests.get(url).text\n",
        "\n",
        "text = BeautifulSoup(html, \"lxml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LOLxTWcuNfA",
        "outputId": "4ae7b3de-2bdf-4f43-9bf3-f385cf38ba0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Length:  1130711\n",
            "Unique Characters:  85\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "with open('text.txt', 'r', encoding=\"utf8\") as fp:\n",
        "  text=fp.read()\n",
        "\n",
        "start_idx = text.find(\"THE MYSTERIOUS ISLAND\")\n",
        "end_idx = text.find(\"End of the Project Gutenberg\")\n",
        "text = text[start_idx:end_idx]\n",
        "char_set = set(text)\n",
        "print(\"Total Length: \", len(text))\n",
        "print(\"Unique Characters: \", len(char_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zv2Qg8p0wvzK",
        "outputId": "f2a658b3-e70f-44e0-854e-c147c68238b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text encoded shape: (1130711,)\n",
            "THE MYSTERIOUS  == Encoding ==> [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n",
            "[37 47 40 29 42 32] == Reverse ==> ISLAND\n"
          ]
        }
      ],
      "source": [
        "chars_sorted = sorted(char_set)\n",
        "char2int = {ch:i for i, ch in enumerate(chars_sorted)}\n",
        "char_array = np.array(chars_sorted)\n",
        "text_encoded = np.array(\n",
        "    [char2int[ch] for ch in text],\n",
        "    dtype=np.int32\n",
        ")\n",
        "print('Text encoded shape:', text_encoded.shape)\n",
        "print(text[:15], '== Encoding ==>', text_encoded[:15])\n",
        "print(text_encoded[15:21], '== Reverse ==>', ''.join(char_array[text_encoded[15:21]]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_sorted"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HM7NpYkrQi3K",
        "outputId": "e4b1282e-f020-4f2c-cf39-4f3563edee39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '\"',\n",
              " '$',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '=',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '‘',\n",
              " '’',\n",
              " '“',\n",
              " '”']"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkR95eIz0OrJ",
        "outputId": "1fa631a4-ee99-417e-d63e-56ae2fe07160"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\n', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-',\n",
              "       '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':',\n",
              "       ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J',\n",
              "       'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
              "       'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',\n",
              "       'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w',\n",
              "       'x', 'y', 'z', '‘', '’', '“', '”'], dtype='<U1')"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "char_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da8T3XWyxg4M",
        "outputId": "0852c3dc-39aa-4a63-eb69-991bb8da44a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48 -> T\n",
            "36 -> H\n",
            "33 -> E\n",
            "1 ->  \n",
            "41 -> M\n"
          ]
        }
      ],
      "source": [
        "for ex in text_encoded[:5]:\n",
        "  print(\"{} -> {}\".format(ex, char_array[ex]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_encoded = text_encoded[:500000]"
      ],
      "metadata": {
        "id": "BxwNXEVaQ4zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lru6bmofy217"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "seq_length = 40\n",
        "chunk_size = seq_length + 1\n",
        "text_chunks = [text_encoded[i:i+chunk_size]\n",
        "               for i in range(len(text_encoded)-chunk_size)]\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "  def __init__(self, text_chunks):\n",
        "    self.text_chunks = text_chunks\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.text_chunks)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    text_chunk = self.text_chunks[idx]\n",
        "    return text_chunk[:-1].long(), text_chunk[1:].long()\n",
        "\n",
        "seq_dataset = TextDataset(torch.tensor(text_chunks))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJGPaxXpzvSv",
        "outputId": "c517fb7c-44a3-47de-d103-351335fbc8ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Input (x):  'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n",
            "Target (y):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
            "\n",
            " Input (x):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
            "Target (y):  'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERIO'\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i, (seq, target) in enumerate(seq_dataset):\n",
        "  print(\" Input (x): \",\n",
        "        repr(\"\".join(char_array[seq])))\n",
        "  print(\"Target (y): \",\n",
        "        repr(\"\".join(char_array[target])))\n",
        "  print()\n",
        "  if i==1:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGrHOOVh2jkX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 64\n",
        "torch.manual_seed(1)\n",
        "seq_dl = DataLoader(seq_dataset, batch_size=batch_size,\n",
        "                    shuffle=True, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc8f5wGS2vl5"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embed_dim, rnn_hidden_size):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "    self.rnn_hidden_size = rnn_hidden_size\n",
        "    self.rnn = nn.LSTM(embed_dim, rnn_hidden_size,\n",
        "                       batch_first=True)\n",
        "    self.fc = nn.Linear(rnn_hidden_size, vocab_size)\n",
        "\n",
        "  def forward(self, x, hidden, cell):\n",
        "    out = self.embedding(x).unsqueeze(1)\n",
        "    out, (hidden, cell) = self.rnn(out, (hidden, cell))\n",
        "    out = self.fc(out).reshape(out.size(0), -1)\n",
        "    return out, hidden, cell\n",
        "\n",
        "  def init_hidden(self, batch_size):\n",
        "    hidden = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
        "    cell = torch.zeros(1, batch_size, self.rnn_hidden_size)\n",
        "    return hidden, cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HL9pvjFZ5aIU",
        "outputId": "b00ecaa4-8464-40b9-ccd0-3c692ed16648"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(85, 256)\n",
              "  (rnn): LSTM(256, 128, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=85, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ],
      "source": [
        "vocab_size = len(char_array)\n",
        "embed_dim = 256\n",
        "rnn_hidden_size = 128\n",
        "torch.manual_seed(1)\n",
        "model = RNN(vocab_size, embed_dim, rnn_hidden_size)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in model.parameters():\n",
        "  print(i.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXW6or1PX5Ng",
        "outputId": "89c53c47-0b30-4443-8fd4-95c349781bd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([85, 256])\n",
            "torch.Size([512, 256])\n",
            "torch.Size([512, 128])\n",
            "torch.Size([512])\n",
            "torch.Size([512])\n",
            "torch.Size([85, 128])\n",
            "torch.Size([85])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcM7rfkF5NZE"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKsc4avJ5wZX",
        "outputId": "8724162d-a49d-41ec-b285-f2bf57e90aab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss: 4.4611\n",
            "Epoch 500 loss: 1.8934\n",
            "Epoch 1000 loss: 1.7013\n",
            "Epoch 1500 loss: 1.5970\n",
            "Epoch 2000 loss: 1.5332\n",
            "Epoch 2500 loss: 1.4199\n",
            "Epoch 3000 loss: 1.4188\n",
            "Epoch 3500 loss: 1.3825\n",
            "Epoch 4000 loss: 1.3721\n",
            "Epoch 4500 loss: 1.3530\n",
            "Epoch 5000 loss: 1.3726\n",
            "Epoch 5500 loss: 1.3605\n",
            "Epoch 6000 loss: 1.3532\n",
            "Epoch 6500 loss: 1.3340\n",
            "Epoch 7000 loss: 1.3798\n",
            "Epoch 7500 loss: 1.2984\n",
            "Epoch 8000 loss: 1.2774\n",
            "Epoch 8500 loss: 1.2823\n",
            "Epoch 9000 loss: 1.2736\n",
            "Epoch 9500 loss: 1.2789\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10000\n",
        "torch.manual_seed(1)\n",
        "for epoch in range(num_epochs):\n",
        "  hidden, cell = model.init_hidden(batch_size)\n",
        "  seq_batch, target_batch = next(iter(seq_dl))\n",
        "  optimizer.zero_grad()\n",
        "  loss = 0\n",
        "  for c in range(seq_length):\n",
        "    pred, hidden, cell = model(seq_batch[:, c], hidden, cell)\n",
        "    loss += loss_fn(pred, target_batch[:, c])\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  loss = loss.item() / seq_length\n",
        "  if epoch % 500 == 0:\n",
        "    print(f\"Epoch {epoch} loss: {loss:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}